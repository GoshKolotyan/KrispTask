# Training args
training:
  output_dir: "./wav2vec2-armenian-frozen"
  group_by_length: true
  per_device_train_batch_size: 32  # RTX 3060 can handle larger batches
  per_device_eval_batch_size: 16
  gradient_accumulation_steps: 2   # Simulates batch_size=32
  eval_strategy: "steps"
  num_train_epochs: 10
  gradient_checkpointing: true
  fp16: false
  save_steps: 200
  eval_steps: 200
  logging_steps: 50
  learning_rate: 5e-5
  warmup_steps: 200
  save_total_limit: 4
  push_to_hub: true
  save_strategy: "no" #for quntization

model:
  name: "facebook/w2v-bert-2.0"
  
  unk_token: "[UNK]"
  pad_token: "[PAD]"
  word_delimiter_token: "|"
  tokenizer_path: './'
  
  attention_dropout: 0.0
  hidden_dropout: 0.0
  feat_proj_dropout: 0.0
  mask_time_prob: 0.0
  layerdrop: 0.0
  
  ctc_loss_reduction: "mean"
  add_adapter: true
  freeze_feature_layers: true

dataset:
  path: "mozilla-foundation/common_voice_16_0"
  language_code: "hy-AM"
  sampling_rate: 16000

repository:
  name: "w2v-bert-2.0-armenian-frozen"

text_processing:
  chars_to_remove_regex: '[,\?\.\!\-\;\:\""%\"«»՚՛՜՝՞։֊…()\-\.,:`´''’]'

authentication:
  hf_token: "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"

quantization:
  enabled: true
  bits: 4                   
  quant_type: "nf4"         
  double_quant: false        # not good result with double quantization
  compute_dtype: "float32" 
  int8_threshold: 6.0       
lora:
  rank: 32                  # Higher rank for better adaptation (16-64 recommended)
  alpha: 64                 # Usually 2x rank
  target_modules: 
    - "linear_q" 
    - "linear_k" 
    - "linear_v" 
    - "linear_out"
    - "intermediate_dense"
    - "output_dense"
  dropout: 0.1
